from __future__ import annotations
import time
import copy
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field, asdict
import numpy as np
from src.config import config
from src.shared.logger import get_logger

logger = get_logger("l3.auto_tuner")

@dataclass
class BatchState:
    batch_id: int
    timestamp: float
    best_score: float
    mean_topk_score: float
    pass_rate_s1: float
    pass_rate_s2: float
    trade_count_mean_topk: float
    zero_trade_ratio_topk: float
    diversity_mean_topk: float
    duplicate_ratio_topk: float
    exception_count: int
    regime: str
    search_profile_mix: Dict[str, float] = field(default_factory=dict)

@dataclass
class InterventionPlan:
    intervention_id: str
    cause: str
    levers: Dict[str, Any]
    start_batch: int
    duration: int
    expected_metrics: List[str]
    initial_values: Dict[str, Any]
    status: str = "ACTIVE" # ACTIVE, SUCCESS, FAILED, ROLLBACK

class AutoTuner:
    """
    [V16] Advanced Self-Correcting Auto-Tuner
    Classifies "RIGID" states into specific causes and applies targeted interventions.
    """
    def __init__(self):
        self.history: List[BatchState] = []
        self.interventions: List[InterventionPlan] = []
        self.ema_best_score = None
        self.ema_topk_score = None
        
        # Levers tracked by tuner
        self.current_levers = {
            "mutation_strength": 0.3,
            "diversity_pressure": 0.8,
            "s1_threshold_adjust": 0.0,
            "reward_w_trades": config.REWARD_W_TRADES,
            "reward_w_mdd": config.REWARD_W_MDD,
            "reward_w_return": config.REWARD_W_RETURN,
            "search_profile_mix": None, # If None, use agent default
            "indicator_swap_prob": config.AUTOTUNE_INDICATOR_SWAP_PROB
        }

    def process_diagnostics(self, diag: Dict[str, Any], extra_info: Dict[str, Any]):
        """
        Unified entry point from infinite_loop.
        Maps OperationalQACollector report to BatchState.
        """
        try:
            state = BatchState(
                batch_id=extra_info.get("batch_id", 0),
                timestamp=diag.get("timestamp", time.time()),
                best_score=diag.get("best_score", config.EVAL_SCORE_MIN),
                mean_topk_score=np.mean(diag.get("performance_stats", {}).get("scores", [config.EVAL_SCORE_MIN])),
                pass_rate_s1=extra_info.get("pass_rate_s1", 0.0),
                pass_rate_s2=diag.get("pass_rate", 0.0),
                trade_count_mean_topk=diag.get("mean_tpy", 0.0),
                zero_trade_ratio_topk=diag.get("zero_trade_ratio", 0.0),
                diversity_mean_topk=1.0 - diag.get("similarity", {}).get("avg_jaccard", 0.0),
                duplicate_ratio_topk=diag.get("similarity", {}).get("collision_rate", 0.0),
                exception_count=extra_info.get("exception_count", 0),
                regime=diag.get("regime", "UNKNOWN"),
                search_profile_mix=extra_info.get("search_profile_mix", {})
            )
            self.record_batch(state)
        except Exception as e:
            logger.error(f"[AutoTuner] Failed to process diagnostics: {e}")

    def record_batch(self, state: BatchState):
        self.history.append(state)
        if len(self.history) > config.AUTOTUNE_HISTORY_SIZE:
            self.history.pop(0)
            
        # Update EMA
        if self.ema_best_score is None:
            self.ema_best_score = state.best_score
            self.ema_topk_score = state.mean_topk_score
        else:
            alpha = 0.2
            self.ema_best_score = (1-alpha) * self.ema_best_score + alpha * state.best_score
            self.ema_topk_score = (1-alpha) * self.ema_topk_score + alpha * state.mean_topk_score

        self._check_interventions(state.batch_id)
        self._analyze_and_act(state)
        
        # Log status
        active = [p for p in self.interventions if p.status == "ACTIVE"]
        if active:
            logger.info(f"[AutoTuner] Active Intervention: {active[0].intervention_id} ({active[0].cause})")

    def _check_interventions(self, current_batch: int):
        """Verifies if active interventions met their goals or need rollback."""
        for plan in self.interventions:
            if plan.status == "ACTIVE" and current_batch >= plan.start_batch + plan.duration:
                # Evaluation time
                success = self._evaluate_intervention(plan)
                if success:
                    plan.status = "SUCCESS"
                    logger.info(f"[AutoTuner] âœ… Intervention {plan.intervention_id} SUCCESS. Maintaining levers.")
                else:
                    plan.status = "FAILED"
                    logger.warning(f"[AutoTuner] âŒ Intervention {plan.intervention_id} FAILED. Rolling back.")
                    self._rollback(plan)

    def _analyze_and_act(self, current: BatchState):
        """Root cause analysis and intervention strategy selection."""
        # Need at least a few batches to see trends
        if len(self.history) < 3:
            return

        cause = self._classify_cause(current)
        if cause == "HEALTHY":
            return

        # Start new intervention if not already tracking an active one
        if any(p.status == "ACTIVE" for p in self.interventions):
            return

        self._apply_intervention(cause, current.batch_id)

    def _classify_cause(self, current: BatchState) -> str:
        """Heuristic-based Cause Classification (A-F)."""
        
        # 0. Infrastructure check (F)
        if current.exception_count > 5:
            return "INFRA_NOISE"

        # 1. Rigidity/Stagnation check
        # Best score improvement over N batches
        best_scores = [s.best_score for s in self.history]
        recent_best = np.max(best_scores[-3:])
        past_best = np.max(best_scores[:-3]) if len(best_scores) > 3 else best_scores[0]
        improvement = recent_best - past_best
        
        is_rigid = improvement < config.AUTOTUNE_RIGID_THRESHOLD
        
        if is_rigid:
            # ì›ì¸ A: í•„í„°/ê²Œì´íŠ¸ ê³¼ë³´ìˆ˜ (Pass Rate Too Low)
            if current.pass_rate_s1 < 0.10 or current.pass_rate_s2 < 0.05:
                return "PASS_RATE_TOO_LOW"
            
            # ì›ì¸ B: ìœ ì „ì  ë‹¤ì–‘ì„± ë¶•ê´´
            if current.duplicate_ratio_topk > 0.4 or current.diversity_mean_topk < config.AUTOTUNE_DIVERSITY_TARGET:
                return "DIVERSITY_COLLAPSE"
                
            # ì›ì¸ D: ê±°ë˜ ì—†ìŒ
            if current.zero_trade_ratio_topk > 0.4 or current.trade_count_mean_topk < 5:
                return "NO_TRADE"
                
            # ì›ì¸ E: ë ˆì§ ë¶ˆì¼ì¹˜ (ìµœê·¼ ë ˆì§ ë³€í™”ê°€ ìˆì—ˆëŠ”ì§€ ì²´í¬ - ë‹¨ìˆœí™”)
            if len(self.history) >= 2 and self.history[-1].regime != self.history[-2].regime:
                return "REGIME_MISMATCH"

            # ì›ì¸ C: íƒìƒ‰ ê³µê°„ ì¢ìŒ
            return "SPACE_TOO_NARROW"

        # ë¶•ê´´ ì²´í¬ (COLLAPSE)
        if current.pass_rate_s2 < 0.01 and current.best_score < config.EVAL_SCORE_MIN * 0.5:
            return "COLLAPSE"

        return "HEALTHY"

    def _apply_intervention(self, cause: str, batch_id: int):
        plan_id = f"INT-{batch_id}-{cause[:4]}"
        levers = {}
        expected = []
        initial = {}

        if cause == "PASS_RATE_TOO_LOW":
            # ì¡°ì¹˜: ì„ê³„ì¹˜ ì™„í™”, epsilon ì†Œí­ ì¦ê°€
            levers = {
                "s1_threshold_adjust": self.current_levers["s1_threshold_adjust"] - 0.05,
                "reward_w_mdd": self.current_levers["reward_w_mdd"] * 0.8 # Relax MDD penalty
            }
            expected = ["pass_rate_s1", "pass_rate_s2"]
            
        elif cause == "DIVERSITY_COLLAPSE":
            # ì¡°ì¹˜: ë‹¤ì–‘ì„± ì••ë ¥ ë° ëŒì—°ë³€ì´ ê°•í™”
            levers = {
                "diversity_pressure": min(1.0, self.current_levers["diversity_pressure"] + 0.1),
                "mutation_strength": min(1.0, self.current_levers["mutation_strength"] + 0.2),
                "indicator_swap_prob": 0.5
            }
            expected = ["diversity_mean_topk", "duplicate_ratio_topk"]
            
        elif cause == "NO_TRADE":
            # ì¡°ì¹˜: ê±°ë˜ìˆ˜ í˜ë„í‹° ê°•í™”, ì ê·¹ì  í”„ë¡œíŒŒì¼ ìœ ë„
            levers = {
                "reward_w_trades": self.current_levers["reward_w_trades"] * 2.0,
                "search_profile_mix": {"SCALPING_FAST": 0.6, "TREND": 0.4} # Hardcoded for now
            }
            expected = ["zero_trade_ratio_topk", "trade_count_mean_topk"]
            
        elif cause == "SPACE_TOO_NARROW":
            # ì¡°ì¹˜: indicator pool í™•ì¥ ìœ ë„ (mutation ê°•ë„ ë° ìœ í˜• ì¡°ì ˆ)
            levers = {
                "mutation_strength": 0.7,
                "indicator_swap_prob": 0.8
            }
            expected = ["best_score", "diversity_mean_topk"]
            
        elif cause == "REGIME_MISMATCH":
            # ì¡°ì¹˜: í”„ë¡œíŒŒì¼ ë¯¹ìŠ¤ ë¶„ì‚° (Exploration ê°•í™”)
            levers = {
                "search_profile_mix": {"SCALPING_FAST": 0.25, "MEANREV": 0.25, "TREND": 0.25, "DEFENSIVE": 0.25}
            }
            expected = ["best_score"]

        elif cause == "INFRA_NOISE":
            # ì¡°ì¹˜: ì•ˆì „ì¥ì¹˜ (ì—¬ê¸°ì„œëŠ” ë¡œê¹… ë° ì„ê³„ì¹˜ ì†Œí­ ì¡°ì •ë§Œ)
            levers = {"s1_threshold_adjust": 0.0} # Reset
            expected = ["exception_count"]
            
        elif cause == "COLLAPSE":
            # ì¡°ì¹˜: ê¸´ê¸‰ ëŒ€í”¼ (Epsilon Reheat ìœ ë„ ë“±ì€ Agentê°€ í•˜ê² ì§€ë§Œ ì—¬ê¸°ì„œë„ ê±°ë“¦)
            levers = {
                "s1_threshold_adjust": 0.0,
                "mutation_strength": 0.8,
                "reward_w_mdd": config.REWARD_W_MDD * 1.5 # Protect
            }
            expected = ["pass_rate_s2", "best_score"]
        
        if not levers:
            return

        # Snapshot initials and apply
        for k, v in levers.items():
            initial[k] = self.current_levers.get(k)
            self.current_levers[k] = v

        plan = InterventionPlan(
            intervention_id=plan_id,
            cause=cause,
            levers=levers,
            start_batch=batch_id,
            duration=config.AUTOTUNE_INTERVENTION_M_BATCHES,
            expected_metrics=expected,
            initial_values=initial
        )
        self.interventions.append(plan)
        logger.warning(f"[AutoTuner] ğŸš€ New Intervention Applied: {plan_id}\nCause: {cause}\nLevers: {levers}")

    def _evaluate_intervention(self, plan: InterventionPlan) -> bool:
        """Compares current state with state before intervention."""
        if len(self.history) < 2:
            return True
            
        current = self.history[-1]
        past = None
        for s in reversed(self.history[:-1]):
            if s.batch_id <= plan.start_batch:
                past = s
                break
        
        if not past:
            return True # Not enough data to fail

        # Check if any expected metric improved
        improvements = 0
        for metric in plan.expected_metrics:
            curr_val = getattr(current, metric, 0)
            past_val = getattr(past, metric, 0)
            
            # Directional success check
            if metric in ["pass_rate_s1", "pass_rate_s2", "best_score", "diversity_mean_topk", "trade_count_mean_topk"]:
                if curr_val > past_val: improvements += 1
            if metric in ["duplicate_ratio_topk", "zero_trade_ratio_topk", "exception_count"]:
                if curr_val < past_val: improvements += 1
                
        # Also check if best score overall improved (ultimate goal)
        if current.best_score > past.best_score:
            improvements += 1
            
        return improvements > 0

    def _rollback(self, plan: InterventionPlan):
        for k, v in plan.initial_values.items():
            self.current_levers[k] = v
        logger.info(f"[AutoTuner] Rollback successful for {plan.intervention_id}")

    def get_levers(self) -> Dict[str, Any]:
        return self.current_levers

_tuner_instance = None

def get_auto_tuner() -> AutoTuner:
    global _tuner_instance
    if _tuner_instance is None:
        _tuner_instance = AutoTuner()
    return _tuner_instance
